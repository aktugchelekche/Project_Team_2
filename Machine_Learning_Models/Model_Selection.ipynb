{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,MinMaxScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from config import db_password\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score ,confusion_matrix ,classification_report\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>year</th>\n",
       "      <th>popularity</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Chainsmokers</td>\n",
       "      <td>#SELFIE - Original Mix</td>\n",
       "      <td>183750</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.263</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2480</td>\n",
       "      <td>0.01350</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>0.660</td>\n",
       "      <td>127.955</td>\n",
       "      <td>pop, Dance/Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>will.i.am</td>\n",
       "      <td>#thatPOWER</td>\n",
       "      <td>279506</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.608</td>\n",
       "      <td>6</td>\n",
       "      <td>-6.096</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.00112</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>0.402</td>\n",
       "      <td>127.999</td>\n",
       "      <td>hip hop, pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>'Till I Collapse</td>\n",
       "      <td>297786</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.847</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.237</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.06220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.100</td>\n",
       "      <td>171.447</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sean Paul</td>\n",
       "      <td>(When You Gonna) Give It Up to Me (feat. Keysh...</td>\n",
       "      <td>243880</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.761</td>\n",
       "      <td>8</td>\n",
       "      <td>-3.040</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.06700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.718</td>\n",
       "      <td>95.824</td>\n",
       "      <td>hip hop, pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>...Ready For It?</td>\n",
       "      <td>208186</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.764</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.05270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.417</td>\n",
       "      <td>160.015</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist                                               song  \\\n",
       "0  The Chainsmokers                             #SELFIE - Original Mix   \n",
       "1         will.i.am                                         #thatPOWER   \n",
       "2            Eminem                                   'Till I Collapse   \n",
       "3         Sean Paul  (When You Gonna) Give It Up to Me (feat. Keysh...   \n",
       "4      Taylor Swift                                   ...Ready For It?   \n",
       "\n",
       "   duration_ms  explicit  year  popularity  danceability  energy  key  \\\n",
       "0       183750         0  2014           0         0.789   0.915    0   \n",
       "1       279506         0  2013           1         0.797   0.608    6   \n",
       "2       297786         1  2002           1         0.548   0.847    1   \n",
       "3       243880         0  2006           0         0.711   0.761    8   \n",
       "4       208186         0  2017           1         0.613   0.764    2   \n",
       "\n",
       "   loudness  mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0    -3.263     1       0.2480       0.01350          0.000009    0.0818   \n",
       "1    -6.096     0       0.0584       0.00112          0.000077    0.0748   \n",
       "2    -3.237     1       0.1860       0.06220          0.000000    0.0816   \n",
       "3    -3.040     1       0.2250       0.06700          0.000000    0.0410   \n",
       "4    -6.509     1       0.1360       0.05270          0.000000    0.1970   \n",
       "\n",
       "   valence    tempo                  genre  \n",
       "0    0.660  127.955  pop, Dance/Electronic  \n",
       "1    0.402  127.999           hip hop, pop  \n",
       "2    0.100  171.447                hip hop  \n",
       "3    0.718   95.824           hip hop, pop  \n",
       "4    0.417  160.015                    pop  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create connection to server \n",
    "db_string = f\"postgresql://postgres:{db_password}@127.0.0.1:5432/songs_data\"\n",
    "#Create Engine\n",
    "engine = create_engine(db_string)\n",
    "# Import Table from Database \n",
    "songs_df = pd.read_sql_table(\"songs_processed\" , con=engine)\n",
    "\n",
    "songs_df = songs_df.drop(\"index\",axis=1)\n",
    "\n",
    "songs_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Enginering : \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = pd.get_dummies(songs_df, columns=['mode','key','explicit', 'year'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating columns for each genre listed in the dataset. Some songs belong to mupltiple genres\n",
    "\n",
    "def extract_genres(df_column):\n",
    "    df_column = [item.casefold() for item in df_column] #casefold all strings\n",
    "    df_column = [item.split(', ') for item in df_column] #convert multiple genre strings into lists\n",
    "    flat_list = [x for xs in df_column for x in xs] #flatten list of lists\n",
    "    return list(np.unique(flat_list)) #return unique values in the flattened list\n",
    "\n",
    "def get_genre_dummies(df,df_genre_column):\n",
    "    df_genre_column = [item.casefold() for item in df_genre_column] #casefold all strings\n",
    "    labels = extract_genres(df_genre_column) #unique genres\n",
    "    for i, item in enumerate(labels):\n",
    "        df[labels[i]] = [1 if labels[i] in genre else 0 for genre in df_genre_column] #one-hot encoding\n",
    "\n",
    "#Add dummy variables to indicate genre for each song\n",
    "get_genre_dummies(songs_df,songs_df['genre'])    \n",
    "songs_df=songs_df.drop('genre', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df=songs_df.drop(['artist' , 'song'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>popularity</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>...</th>\n",
       "      <th>folk/acoustic</th>\n",
       "      <th>hip hop</th>\n",
       "      <th>jazz</th>\n",
       "      <th>latin</th>\n",
       "      <th>metal</th>\n",
       "      <th>pop</th>\n",
       "      <th>r&amp;b</th>\n",
       "      <th>rock</th>\n",
       "      <th>set()</th>\n",
       "      <th>world/traditional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.915</td>\n",
       "      <td>-3.263</td>\n",
       "      <td>0.2480</td>\n",
       "      <td>0.01350</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>0.660</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>279506</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.608</td>\n",
       "      <td>-6.096</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.00112</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>0.402</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297786</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-3.237</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.06220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243880</td>\n",
       "      <td>0</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.761</td>\n",
       "      <td>-3.040</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.06700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.718</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208186</td>\n",
       "      <td>1</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.764</td>\n",
       "      <td>-6.509</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.05270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.417</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>350120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.729</td>\n",
       "      <td>-6.815</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.05380</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.217</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>205920</td>\n",
       "      <td>1</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.713</td>\n",
       "      <td>-5.507</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.04000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.354</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>238320</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.724</td>\n",
       "      <td>-3.724</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.21300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.604</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>218146</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.520</td>\n",
       "      <td>-6.136</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.129</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>184153</td>\n",
       "      <td>1</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-12.808</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.11300</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.237</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2051 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      duration_ms  popularity  danceability  energy  loudness  speechiness  \\\n",
       "0          183750           0         0.789   0.915    -3.263       0.2480   \n",
       "1          279506           1         0.797   0.608    -6.096       0.0584   \n",
       "2          297786           1         0.548   0.847    -3.237       0.1860   \n",
       "3          243880           0         0.711   0.761    -3.040       0.2250   \n",
       "4          208186           1         0.613   0.764    -6.509       0.1360   \n",
       "...           ...         ...           ...     ...       ...          ...   \n",
       "2046       350120           1         0.487   0.729    -6.815       0.2710   \n",
       "2047       205920           1         0.699   0.713    -5.507       0.0594   \n",
       "2048       238320           1         0.418   0.724    -3.724       0.0964   \n",
       "2049       218146           1         0.585   0.520    -6.136       0.0712   \n",
       "2050       184153           1         0.566   0.366   -12.808       0.0280   \n",
       "\n",
       "      acousticness  instrumentalness  liveness  valence  ...  folk/acoustic  \\\n",
       "0          0.01350          0.000009    0.0818    0.660  ...              0   \n",
       "1          0.00112          0.000077    0.0748    0.402  ...              0   \n",
       "2          0.06220          0.000000    0.0816    0.100  ...              0   \n",
       "3          0.06700          0.000000    0.0410    0.718  ...              0   \n",
       "4          0.05270          0.000000    0.1970    0.417  ...              0   \n",
       "...            ...               ...       ...      ...  ...            ...   \n",
       "2046       0.05380          0.000004    0.4400    0.217  ...              0   \n",
       "2047       0.04000          0.000003    0.2940    0.354  ...              0   \n",
       "2048       0.21300          0.000000    0.1120    0.604  ...              0   \n",
       "2049       0.12400          0.000070    0.1310    0.129  ...              0   \n",
       "2050       0.11300          0.181000    0.1550    0.237  ...              0   \n",
       "\n",
       "      hip hop  jazz  latin  metal  pop  r&b  rock  set()  world/traditional  \n",
       "0           0     0      0      0    1    0     0      0                  0  \n",
       "1           1     0      0      0    1    0     0      0                  0  \n",
       "2           1     0      0      0    0    0     0      0                  0  \n",
       "3           1     0      0      0    1    0     0      0                  0  \n",
       "4           0     0      0      0    1    0     0      0                  0  \n",
       "...       ...   ...    ...    ...  ...  ...   ...    ...                ...  \n",
       "2046        1     0      0      0    0    0     0      0                  0  \n",
       "2047        0     0      0      0    1    0     0      0                  0  \n",
       "2048        1     0      0      0    1    1     0      0                  0  \n",
       "2049        1     0      0      0    0    0     0      0                  0  \n",
       "2050        0     0      0      0    1    0     1      0                  0  \n",
       "\n",
       "[2051 rows x 61 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset to Train and Test \n",
    "Target = \"Popularity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aktugcilekci/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = songs_df[\"popularity\"].values\n",
    "X = songs_df.drop([\"popularity\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =  0.2 ,random_state=78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standarizing \n",
    "\n",
    "We are using <code> StardardScaler</code> to standrize our dataset  then fit it to model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Training\n",
    "\n",
    "We will fir and train our model with follwing Algoritms :\n",
    "\n",
    "* Nearul Network\n",
    "* Random Forest \n",
    "* SVM\n",
    "* Logistic Regression \n",
    "* Gradient Boost\n",
    "\n",
    "After comparing model we will select and save our model .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Nearul Network   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 120)               7320      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                6050      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,421\n",
      "Trainable params: 13,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "#Added 3rd Layer and Additional Neurons \n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 50\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer  \n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# # Third hidden layer\n",
    "#nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints/\", exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\"\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48/52 [==========================>...] - ETA: 0s - loss: 786.7449 - accuracy: 0.4714\n",
      "Epoch 1: saving model to checkpoints/weights.01.hdf5\n",
      "52/52 [==============================] - 1s 5ms/step - loss: 770.5579 - accuracy: 0.4720\n",
      "Epoch 2/100\n",
      "47/52 [==========================>...] - ETA: 0s - loss: 681.7683 - accuracy: 0.4987\n",
      "Epoch 2: saving model to checkpoints/weights.02.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 682.5809 - accuracy: 0.5024\n",
      "Epoch 3/100\n",
      "50/52 [===========================>..] - ETA: 0s - loss: 288.2768 - accuracy: 0.5063\n",
      "Epoch 3: saving model to checkpoints/weights.03.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 289.0231 - accuracy: 0.5049\n",
      "Epoch 4/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 308.4781 - accuracy: 0.5018\n",
      "Epoch 4: saving model to checkpoints/weights.04.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 307.8399 - accuracy: 0.5024\n",
      "Epoch 5/100\n",
      "45/52 [========================>.....] - ETA: 0s - loss: 395.7680 - accuracy: 0.5056\n",
      "Epoch 5: saving model to checkpoints/weights.05.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 379.6749 - accuracy: 0.5037\n",
      "Epoch 6/100\n",
      "50/52 [===========================>..] - ETA: 0s - loss: 357.5233 - accuracy: 0.4931\n",
      "Epoch 6: saving model to checkpoints/weights.06.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 357.5351 - accuracy: 0.4963\n",
      "Epoch 7/100\n",
      "46/52 [=========================>....] - ETA: 0s - loss: 453.8481 - accuracy: 0.5177\n",
      "Epoch 7: saving model to checkpoints/weights.07.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 429.2947 - accuracy: 0.5183\n",
      "Epoch 8/100\n",
      "47/52 [==========================>...] - ETA: 0s - loss: 396.5148 - accuracy: 0.4907\n",
      "Epoch 8: saving model to checkpoints/weights.08.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 380.6334 - accuracy: 0.4890\n",
      "Epoch 9/100\n",
      "45/52 [========================>.....] - ETA: 0s - loss: 401.2849 - accuracy: 0.4924\n",
      "Epoch 9: saving model to checkpoints/weights.09.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 369.5011 - accuracy: 0.4988\n",
      "Epoch 10/100\n",
      "39/52 [=====================>........] - ETA: 0s - loss: 367.4253 - accuracy: 0.5056\n",
      "Epoch 10: saving model to checkpoints/weights.10.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 342.0310 - accuracy: 0.5073\n",
      "Epoch 11/100\n",
      "46/52 [=========================>....] - ETA: 0s - loss: 423.6553 - accuracy: 0.4912\n",
      "Epoch 11: saving model to checkpoints/weights.11.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 415.7984 - accuracy: 0.4817\n",
      "Epoch 12/100\n",
      "48/52 [==========================>...] - ETA: 0s - loss: 488.0353 - accuracy: 0.4740\n",
      "Epoch 12: saving model to checkpoints/weights.12.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 461.4286 - accuracy: 0.4780\n",
      "Epoch 13/100\n",
      "44/52 [========================>.....] - ETA: 0s - loss: 327.3693 - accuracy: 0.5050\n",
      "Epoch 13: saving model to checkpoints/weights.13.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 329.3403 - accuracy: 0.5061\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 360.6391 - accuracy: 0.4780\n",
      "Epoch 14: saving model to checkpoints/weights.14.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 360.6391 - accuracy: 0.4780\n",
      "Epoch 15/100\n",
      "47/52 [==========================>...] - ETA: 0s - loss: 393.3110 - accuracy: 0.4820\n",
      "Epoch 15: saving model to checkpoints/weights.15.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 369.0671 - accuracy: 0.4817\n",
      "Epoch 16/100\n",
      "48/52 [==========================>...] - ETA: 0s - loss: 340.6425 - accuracy: 0.5156\n",
      "Epoch 16: saving model to checkpoints/weights.16.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 340.8465 - accuracy: 0.5159\n",
      "Epoch 17/100\n",
      "50/52 [===========================>..] - ETA: 0s - loss: 262.8626 - accuracy: 0.4850\n",
      "Epoch 17: saving model to checkpoints/weights.17.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 264.9132 - accuracy: 0.4890\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 267.8134 - accuracy: 0.5000\n",
      "Epoch 18: saving model to checkpoints/weights.18.hdf5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 267.8134 - accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 298.5344 - accuracy: 0.4936\n",
      "Epoch 19: saving model to checkpoints/weights.19.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 297.8787 - accuracy: 0.4939\n",
      "Epoch 20/100\n",
      "44/52 [========================>.....] - ETA: 0s - loss: 217.7112 - accuracy: 0.5085\n",
      "Epoch 20: saving model to checkpoints/weights.20.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 241.7639 - accuracy: 0.5085\n",
      "Epoch 21/100\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 283.2556 - accuracy: 0.5045\n",
      "Epoch 21: saving model to checkpoints/weights.21.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 302.9569 - accuracy: 0.5024\n",
      "Epoch 22/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 414.1544 - accuracy: 0.4957\n",
      "Epoch 22: saving model to checkpoints/weights.22.hdf5\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 414.4261 - accuracy: 0.4951\n",
      "Epoch 23/100\n",
      "42/52 [=======================>......] - ETA: 0s - loss: 367.4401 - accuracy: 0.5141\n",
      "Epoch 23: saving model to checkpoints/weights.23.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 446.5625 - accuracy: 0.5183\n",
      "Epoch 24/100\n",
      "42/52 [=======================>......] - ETA: 0s - loss: 195.0212 - accuracy: 0.4896\n",
      "Epoch 24: saving model to checkpoints/weights.24.hdf5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 230.7317 - accuracy: 0.4902\n",
      "Epoch 25/100\n",
      "43/52 [=======================>......] - ETA: 0s - loss: 239.6744 - accuracy: 0.5131\n",
      "Epoch 25: saving model to checkpoints/weights.25.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 273.1825 - accuracy: 0.5110\n",
      "Epoch 26/100\n",
      "43/52 [=======================>......] - ETA: 0s - loss: 189.6705 - accuracy: 0.4855\n",
      "Epoch 26: saving model to checkpoints/weights.26.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 239.2835 - accuracy: 0.4805\n",
      "Epoch 27/100\n",
      "44/52 [========================>.....] - ETA: 0s - loss: 353.3911 - accuracy: 0.5185\n",
      "Epoch 27: saving model to checkpoints/weights.27.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 389.4530 - accuracy: 0.5098\n",
      "Epoch 28/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 415.7631 - accuracy: 0.5043\n",
      "Epoch 28: saving model to checkpoints/weights.28.hdf5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 414.0546 - accuracy: 0.5049\n",
      "Epoch 29/100\n",
      "47/52 [==========================>...] - ETA: 0s - loss: 294.4657 - accuracy: 0.4940\n",
      "Epoch 29: saving model to checkpoints/weights.29.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 296.9808 - accuracy: 0.4939\n",
      "Epoch 30/100\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 378.7440 - accuracy: 0.4751\n",
      "Epoch 30: saving model to checkpoints/weights.30.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 372.0174 - accuracy: 0.4756\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 311.8525 - accuracy: 0.5122\n",
      "Epoch 31: saving model to checkpoints/weights.31.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 311.8525 - accuracy: 0.5122\n",
      "Epoch 32/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 252.6170 - accuracy: 0.5043\n",
      "Epoch 32: saving model to checkpoints/weights.32.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 251.7165 - accuracy: 0.5061\n",
      "Epoch 33/100\n",
      "44/52 [========================>.....] - ETA: 0s - loss: 242.5790 - accuracy: 0.5114\n",
      "Epoch 33: saving model to checkpoints/weights.33.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 254.2672 - accuracy: 0.5073\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 347.1794 - accuracy: 0.4854\n",
      "Epoch 34: saving model to checkpoints/weights.34.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 347.1794 - accuracy: 0.4854\n",
      "Epoch 35/100\n",
      "37/52 [====================>.........] - ETA: 0s - loss: 189.9251 - accuracy: 0.5152\n",
      "Epoch 35: saving model to checkpoints/weights.35.hdf5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 187.7906 - accuracy: 0.5073\n",
      "Epoch 36/100\n",
      "47/52 [==========================>...] - ETA: 0s - loss: 419.9605 - accuracy: 0.4914\n",
      "Epoch 36: saving model to checkpoints/weights.36.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 411.2683 - accuracy: 0.4902\n",
      "Epoch 37/100\n",
      "50/52 [===========================>..] - ETA: 0s - loss: 294.7817 - accuracy: 0.5038\n",
      "Epoch 37: saving model to checkpoints/weights.37.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 296.6942 - accuracy: 0.4988\n",
      "Epoch 38/100\n",
      "50/52 [===========================>..] - ETA: 0s - loss: 264.4654 - accuracy: 0.4994\n",
      "Epoch 38: saving model to checkpoints/weights.38.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 266.4857 - accuracy: 0.4963\n",
      "Epoch 39/100\n",
      "43/52 [=======================>......] - ETA: 0s - loss: 185.0396 - accuracy: 0.5065\n",
      "Epoch 39: saving model to checkpoints/weights.39.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 190.7187 - accuracy: 0.5012\n",
      "Epoch 40/100\n",
      "47/52 [==========================>...] - ETA: 0s - loss: 324.0920 - accuracy: 0.5173\n",
      "Epoch 40: saving model to checkpoints/weights.40.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 309.8047 - accuracy: 0.5195\n",
      "Epoch 41/100\n",
      "50/52 [===========================>..] - ETA: 0s - loss: 263.0965 - accuracy: 0.4975\n",
      "Epoch 41: saving model to checkpoints/weights.41.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 262.9607 - accuracy: 0.4976\n",
      "Epoch 42/100\n",
      "50/52 [===========================>..] - ETA: 0s - loss: 300.4959 - accuracy: 0.4787\n",
      "Epoch 42: saving model to checkpoints/weights.42.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 298.3805 - accuracy: 0.4805\n",
      "Epoch 43/100\n",
      "48/52 [==========================>...] - ETA: 0s - loss: 247.0062 - accuracy: 0.5026\n",
      "Epoch 43: saving model to checkpoints/weights.43.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 248.7569 - accuracy: 0.5024\n",
      "Epoch 44/100\n",
      "48/52 [==========================>...] - ETA: 0s - loss: 262.0051 - accuracy: 0.4837\n",
      "Epoch 44: saving model to checkpoints/weights.44.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 252.7026 - accuracy: 0.4890\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 182.3442 - accuracy: 0.5098\n",
      "Epoch 45: saving model to checkpoints/weights.45.hdf5\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 182.3442 - accuracy: 0.5098\n",
      "Epoch 46/100\n",
      "46/52 [=========================>....] - ETA: 0s - loss: 372.9686 - accuracy: 0.4857\n",
      "Epoch 46: saving model to checkpoints/weights.46.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 366.4021 - accuracy: 0.4915\n",
      "Epoch 47/100\n",
      "42/52 [=======================>......] - ETA: 0s - loss: 277.7822 - accuracy: 0.5052\n",
      "Epoch 47: saving model to checkpoints/weights.47.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 269.5658 - accuracy: 0.5049\n",
      "Epoch 48/100\n",
      "45/52 [========================>.....] - ETA: 0s - loss: 412.3910 - accuracy: 0.5104\n",
      "Epoch 48: saving model to checkpoints/weights.48.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 384.9020 - accuracy: 0.5098\n",
      "Epoch 49/100\n",
      "48/52 [==========================>...] - ETA: 0s - loss: 440.3085 - accuracy: 0.5039\n",
      "Epoch 49: saving model to checkpoints/weights.49.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 416.6897 - accuracy: 0.5061\n",
      "Epoch 50/100\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 308.2343 - accuracy: 0.4866\n",
      "Epoch 50: saving model to checkpoints/weights.50.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 328.5094 - accuracy: 0.4866\n",
      "Epoch 51/100\n",
      "43/52 [=======================>......] - ETA: 0s - loss: 371.6350 - accuracy: 0.4760\n",
      "Epoch 51: saving model to checkpoints/weights.51.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 374.4601 - accuracy: 0.4768\n",
      "Epoch 52/100\n",
      "47/52 [==========================>...] - ETA: 0s - loss: 171.6056 - accuracy: 0.4900\n",
      "Epoch 52: saving model to checkpoints/weights.52.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 169.4393 - accuracy: 0.4866\n",
      "Epoch 53/100\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 242.4806 - accuracy: 0.4974\n",
      "Epoch 53: saving model to checkpoints/weights.53.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 239.5529 - accuracy: 0.4988\n",
      "Epoch 54/100\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 133.6517 - accuracy: 0.4904\n",
      "Epoch 54: saving model to checkpoints/weights.54.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 138.6434 - accuracy: 0.4909\n",
      "Epoch 55/100\n",
      "45/52 [========================>.....] - ETA: 0s - loss: 371.7708 - accuracy: 0.4965\n",
      "Epoch 55: saving model to checkpoints/weights.55.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 341.9743 - accuracy: 0.4976\n",
      "Epoch 56/100\n",
      "48/52 [==========================>...] - ETA: 0s - loss: 210.1467 - accuracy: 0.4948\n",
      "Epoch 56: saving model to checkpoints/weights.56.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 204.2695 - accuracy: 0.4915\n",
      "Epoch 57/100\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 205.5723 - accuracy: 0.5077\n",
      "Epoch 57: saving model to checkpoints/weights.57.hdf5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 208.6750 - accuracy: 0.5061\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 422.3206 - accuracy: 0.5061\n",
      "Epoch 58: saving model to checkpoints/weights.58.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 422.3206 - accuracy: 0.5061\n",
      "Epoch 59/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 491.0583 - accuracy: 0.4877\n",
      "Epoch 59: saving model to checkpoints/weights.59.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 489.2671 - accuracy: 0.4890\n",
      "Epoch 60/100\n",
      "37/52 [====================>.........] - ETA: 0s - loss: 329.0844 - accuracy: 0.5093\n",
      "Epoch 60: saving model to checkpoints/weights.60.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 274.4999 - accuracy: 0.5098\n",
      "Epoch 61/100\n",
      "41/52 [======================>.......] - ETA: 0s - loss: 127.1114 - accuracy: 0.4954\n",
      "Epoch 61: saving model to checkpoints/weights.61.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 151.3396 - accuracy: 0.4982\n",
      "Epoch 62/100\n",
      "38/52 [====================>.........] - ETA: 0s - loss: 205.0668 - accuracy: 0.4877\n",
      "Epoch 62: saving model to checkpoints/weights.62.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 238.0849 - accuracy: 0.4854\n",
      "Epoch 63/100\n",
      "48/52 [==========================>...] - ETA: 0s - loss: 327.5475 - accuracy: 0.5039\n",
      "Epoch 63: saving model to checkpoints/weights.63.hdf5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 319.3628 - accuracy: 0.5098\n",
      "Epoch 64/100\n",
      "50/52 [===========================>..] - ETA: 0s - loss: 281.6024 - accuracy: 0.4913\n",
      "Epoch 64: saving model to checkpoints/weights.64.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 285.8234 - accuracy: 0.4878\n",
      "Epoch 65/100\n",
      "47/52 [==========================>...] - ETA: 0s - loss: 157.3179 - accuracy: 0.5180\n",
      "Epoch 65: saving model to checkpoints/weights.65.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 157.5120 - accuracy: 0.5183\n",
      "Epoch 66/100\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 162.0404 - accuracy: 0.4949\n",
      "Epoch 66: saving model to checkpoints/weights.66.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 156.2524 - accuracy: 0.4976\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 195.2341 - accuracy: 0.4744\n",
      "Epoch 67: saving model to checkpoints/weights.67.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 195.2341 - accuracy: 0.4744\n",
      "Epoch 68/100\n",
      "45/52 [========================>.....] - ETA: 0s - loss: 397.3710 - accuracy: 0.5028\n",
      "Epoch 68: saving model to checkpoints/weights.68.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 374.9122 - accuracy: 0.5037\n",
      "Epoch 69/100\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 245.9130 - accuracy: 0.4885\n",
      "Epoch 69: saving model to checkpoints/weights.69.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 241.4692 - accuracy: 0.4902\n",
      "Epoch 70/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 247.7513 - accuracy: 0.4884\n",
      "Epoch 70: saving model to checkpoints/weights.70.hdf5\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 247.4035 - accuracy: 0.4890\n",
      "Epoch 71/100\n",
      "50/52 [===========================>..] - ETA: 0s - loss: 321.0450 - accuracy: 0.5038\n",
      "Epoch 71: saving model to checkpoints/weights.71.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 322.6655 - accuracy: 0.5024\n",
      "Epoch 72/100\n",
      "42/52 [=======================>......] - ETA: 0s - loss: 183.7261 - accuracy: 0.5104\n",
      "Epoch 72: saving model to checkpoints/weights.72.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 177.2107 - accuracy: 0.5061\n",
      "Epoch 73/100\n",
      "46/52 [=========================>....] - ETA: 0s - loss: 135.7232 - accuracy: 0.5177\n",
      "Epoch 73: saving model to checkpoints/weights.73.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 138.1833 - accuracy: 0.5128\n",
      "Epoch 74/100\n",
      "46/52 [=========================>....] - ETA: 0s - loss: 365.8971 - accuracy: 0.5149\n",
      "Epoch 74: saving model to checkpoints/weights.74.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 367.9845 - accuracy: 0.5146\n",
      "Epoch 75/100\n",
      "47/52 [==========================>...] - ETA: 0s - loss: 308.7667 - accuracy: 0.4987\n",
      "Epoch 75: saving model to checkpoints/weights.75.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 297.5534 - accuracy: 0.4988\n",
      "Epoch 76/100\n",
      "46/52 [=========================>....] - ETA: 0s - loss: 314.5969 - accuracy: 0.4857\n",
      "Epoch 76: saving model to checkpoints/weights.76.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 315.7405 - accuracy: 0.4890\n",
      "Epoch 77/100\n",
      "45/52 [========================>.....] - ETA: 0s - loss: 166.9865 - accuracy: 0.5319\n",
      "Epoch 77: saving model to checkpoints/weights.77.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 189.7942 - accuracy: 0.5226\n",
      "Epoch 78/100\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 263.0647 - accuracy: 0.5108\n",
      "Epoch 78: saving model to checkpoints/weights.78.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 260.3752 - accuracy: 0.5159\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 328.7988 - accuracy: 0.4841\n",
      "Epoch 79: saving model to checkpoints/weights.79.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 328.7988 - accuracy: 0.4841\n",
      "Epoch 80/100\n",
      "44/52 [========================>.....] - ETA: 0s - loss: 176.0832 - accuracy: 0.4908\n",
      "Epoch 80: saving model to checkpoints/weights.80.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 164.4247 - accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "48/52 [==========================>...] - ETA: 0s - loss: 214.7212 - accuracy: 0.4961\n",
      "Epoch 81: saving model to checkpoints/weights.81.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 215.8799 - accuracy: 0.4963\n",
      "Epoch 82/100\n",
      "42/52 [=======================>......] - ETA: 0s - loss: 216.2877 - accuracy: 0.5097\n",
      "Epoch 82: saving model to checkpoints/weights.82.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 212.7251 - accuracy: 0.5037\n",
      "Epoch 83/100\n",
      "44/52 [========================>.....] - ETA: 0s - loss: 125.1717 - accuracy: 0.5078\n",
      "Epoch 83: saving model to checkpoints/weights.83.hdf5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 127.3091 - accuracy: 0.5159\n",
      "Epoch 84/100\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 258.1289 - accuracy: 0.4796\n",
      "Epoch 84: saving model to checkpoints/weights.84.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 255.6331 - accuracy: 0.4817\n",
      "Epoch 85/100\n",
      "48/52 [==========================>...] - ETA: 0s - loss: 170.2547 - accuracy: 0.5052\n",
      "Epoch 85: saving model to checkpoints/weights.85.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 192.3480 - accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "44/52 [========================>.....] - ETA: 0s - loss: 373.3479 - accuracy: 0.4972\n",
      "Epoch 86: saving model to checkpoints/weights.86.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 350.8911 - accuracy: 0.4817\n",
      "Epoch 87/100\n",
      "47/52 [==========================>...] - ETA: 0s - loss: 111.7843 - accuracy: 0.5060\n",
      "Epoch 87: saving model to checkpoints/weights.87.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 112.9445 - accuracy: 0.5043\n",
      "Epoch 88/100\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 105.6569 - accuracy: 0.4866\n",
      "Epoch 88: saving model to checkpoints/weights.88.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 105.5436 - accuracy: 0.4866\n",
      "Epoch 89/100\n",
      "45/52 [========================>.....] - ETA: 0s - loss: 147.6183 - accuracy: 0.4778\n",
      "Epoch 89: saving model to checkpoints/weights.89.hdf5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 161.7495 - accuracy: 0.4890\n",
      "Epoch 90/100\n",
      "41/52 [======================>.......] - ETA: 0s - loss: 181.3875 - accuracy: 0.5160\n",
      "Epoch 90: saving model to checkpoints/weights.90.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 174.6263 - accuracy: 0.5146\n",
      "Epoch 91/100\n",
      "47/52 [==========================>...] - ETA: 0s - loss: 323.9996 - accuracy: 0.5106\n",
      "Epoch 91: saving model to checkpoints/weights.91.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 316.4875 - accuracy: 0.5030\n",
      "Epoch 92/100\n",
      "45/52 [========================>.....] - ETA: 0s - loss: 131.6477 - accuracy: 0.5139\n",
      "Epoch 92: saving model to checkpoints/weights.92.hdf5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 150.1459 - accuracy: 0.5140\n",
      "Epoch 93/100\n",
      "44/52 [========================>.....] - ETA: 0s - loss: 252.0983 - accuracy: 0.4929\n",
      "Epoch 93: saving model to checkpoints/weights.93.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 253.3134 - accuracy: 0.4878\n",
      "Epoch 94/100\n",
      "48/52 [==========================>...] - ETA: 0s - loss: 139.6348 - accuracy: 0.4824\n",
      "Epoch 94: saving model to checkpoints/weights.94.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 139.8283 - accuracy: 0.4841\n",
      "Epoch 95/100\n",
      "46/52 [=========================>....] - ETA: 0s - loss: 193.0945 - accuracy: 0.5027\n",
      "Epoch 95: saving model to checkpoints/weights.95.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 179.2442 - accuracy: 0.5043\n",
      "Epoch 96/100\n",
      "37/52 [====================>.........] - ETA: 0s - loss: 203.9315 - accuracy: 0.5034\n",
      "Epoch 96: saving model to checkpoints/weights.96.hdf5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 183.9155 - accuracy: 0.5067\n",
      "Epoch 97/100\n",
      "44/52 [========================>.....] - ETA: 0s - loss: 158.2925 - accuracy: 0.4886\n",
      "Epoch 97: saving model to checkpoints/weights.97.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 152.8439 - accuracy: 0.4866\n",
      "Epoch 98/100\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 178.3810 - accuracy: 0.5147\n",
      "Epoch 98: saving model to checkpoints/weights.98.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 174.7956 - accuracy: 0.5122\n",
      "Epoch 99/100\n",
      "41/52 [======================>.......] - ETA: 0s - loss: 223.9397 - accuracy: 0.4901\n",
      "Epoch 99: saving model to checkpoints/weights.99.hdf5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 216.0078 - accuracy: 0.4976\n",
      "Epoch 100/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 232.4070 - accuracy: 0.5049\n",
      "Epoch 100: saving model to checkpoints/weights.100.hdf5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 232.1097 - accuracy: 0.5049\n"
     ]
    }
   ],
   "source": [
    "# Fit it with 100 epochs \n",
    "fit_model=nn.fit(X_train,y_train,epochs=100, callbacks=[cp_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 - 0s - loss: 0.6298 - accuracy: 0.6323 - 242ms/epoch - 5ms/step\n",
      "Loss: 0.6298380494117737, Accuracy: 0.632317066192627\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_train_scaled,y_train,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 0s - loss: 0.6740 - accuracy: 0.5815 - 50ms/epoch - 4ms/step\n",
      "Loss: 0.6739681363105774, Accuracy: 0.5815085172653198\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random forest model accuracy: 0.582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=78) \n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\" Random forest model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Support Vector Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a linear SVM model\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM  model accuracy: 0.506\n"
     ]
    }
   ],
   "source": [
    "# Fit the data\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions using the test data\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(f\" SVM  model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic Regression model accuracy: 0.506\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Instance \n",
    "log_model = LogisticRegression()\n",
    "# Fit the model \n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "print(f\" Logistic Regression model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.GradientBoosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.667\n",
      "Accuracy score (validation): 0.545\n",
      "\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.674\n",
      "Accuracy score (validation): 0.557\n",
      "\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.703\n",
      "Accuracy score (validation): 0.555\n",
      "\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.719\n",
      "Accuracy score (validation): 0.543\n",
      "\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.735\n",
      "Accuracy score (validation): 0.538\n",
      "\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.738\n",
      "Accuracy score (validation): 0.577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create a classifier object\n",
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    classifier = GradientBoostingClassifier(n_estimators=20,\n",
    "                                            learning_rate=learning_rate,\n",
    "                                            max_features=5,\n",
    "                                            max_depth=3,\n",
    "                                            random_state=0)\n",
    "\n",
    "    # Fit the model\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "\n",
    "    # Score the model\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(\n",
    "        classifier.score(\n",
    "            X_train_scaled,\n",
    "            y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(\n",
    "        classifier.score(\n",
    "            X_test_scaled,\n",
    "            y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Actual\n",
       "0            0       1\n",
       "1            0       0\n",
       "2            0       0\n",
       "3            0       1\n",
       "4            1       1\n",
       "5            0       1\n",
       "6            0       1\n",
       "7            1       0\n",
       "8            0       0\n",
       "9            1       1\n",
       "10           0       1\n",
       "11           0       1\n",
       "12           0       0\n",
       "13           0       0\n",
       "14           0       1\n",
       "15           0       0\n",
       "16           0       1\n",
       "17           0       0\n",
       "18           1       1\n",
       "19           1       0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a learning rate and create classifier\n",
    "classifier = GradientBoostingClassifier(n_estimators=20,\n",
    "                                        learning_rate=0.5,\n",
    "                                        max_features=5,\n",
    "                                        max_depth=3,\n",
    "                                        random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make Prediction\n",
    "predictions = classifier.predict(X_test_scaled)\n",
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5425790754257908\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score : {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected Model \n",
    "Upon comparing Accuracy Scores, Nearul Network generated the highest score as .63 . Therefore we will use this model for our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to HDF5 file\n",
    "nn.save(\"Song_Popularity.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62f8b6f3f1526dcf06cc94e63fd3e284d30328d64214c81b7778bcae0f94190c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
